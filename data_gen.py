import sqlite3
from dataclasses import dataclass
from textwrap import dedent
from typing import Iterator, List, Dict, Any

from diskcache import Cache
import litellm
from litellm import acompletion
from litellm.caching.caching import LiteLLMCacheType, Cache
from local_db import DB_PATH
from data_types import Issue
from pydantic import BaseModel, Field

@dataclass
class IssueSnippet():
    issue_number: int
    title: str
    body: str

def iterate_repo_issues(
    repo_name: str,
    *,
    batch_size: int = 20,
    db_path: str = DB_PATH,
) -> Iterator[List[IssueSnippet]]:
    """Yield batches of GitHub issues for the given repository.

    The function returns an *iterator* where each item is a list (batch) of
    Issue objects whose size is at most ``batch_size``.

    Parameters
    ----------
    repo_name:
        The repository name (case-sensitive) whose issues we want to
        iterate over.
    batch_size:
        Size of the batch to yield on every iteration. Defaults to ``20``.
    db_path:
        Path to the SQLite database. Defaults to the database generated by
        ``local_db``.
    """
    
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row  # access columns by name

    # First, gather *all* issue IDs that belong to this repository
    base_query_ids = """
        SELECT id
        FROM github_issues
        WHERE repo_name = ?
        ORDER BY created_at DESC
        """

    cursor = conn.execute(base_query_ids, (repo_name,))
    all_issue_ids = [row["id"] for row in cursor.fetchall()]

    total = len(all_issue_ids)
    if total == 0:
        conn.close()
        return  # Empty iterator

    # Helper to fetch a batch of Issue objects given a slice of ids
    def _fetch_batch(id_slice: List[int]) -> List[Issue]:
        placeholders = ",".join(["?"] * len(id_slice))
        issues_query = f"""
            SELECT id, repo_name, topic, issue_number, title, body, open, 
                   created_at, updated_at, url, labels, user, comments
            FROM github_issues
            WHERE id IN ({placeholders})
            ORDER BY created_at DESC
        """
        issue_rows = conn.execute(issues_query, id_slice).fetchall()

        batch: List[Issue] = []
        for row in issue_rows:
            batch.append(IssueSnippet(
                issue_number=row["issue_number"],
                title=row["title"],
                body=row["body"],
            ))
        return batch

    # Yield batches lazily
    for start in range(0, total, batch_size):
        id_batch = all_issue_ids[start : start + batch_size]
        yield _fetch_batch(id_batch)

    conn.close()



litellm.cache = Cache(type=LiteLLMCacheType.DISK)


class GeneratedSyntheticQuery(BaseModel):
    question: str
    answer: str
    repo: str
    issue: int
    how_realistic: float = Field(
        ...,
        description="Give a score between 0 and 1 on how realistic this question is. That is, how likely is it that the user would actually ask this question of their inbox?",
    )

class Response(BaseModel):
    questions: List[GeneratedSyntheticQuery]
    
async def generate_synthetic_qa_pairs_for_repo(repo: str, batch: List[IssueSnippet]) -> Response:
    """
    Generate synthetic QA pairs for a given repository.
    """
    # Extract the titles and bodies of the issues
    
    SYSTEM_PROMPT = dedent(
        f"""
        You are an assistant that creates realistic question–answer pairs a human might ask about a github issue in a repo.
        Every answer MUST be fully contained in the provided issue. Do NOT hallucinate.

        Do not include the issue number in the question.

        Respond with a JSON object with the following structure:
        {Response.model_json_schema()}
        """
    ).strip()

    user_query = dedent(
        f"""
        Here are {len(batch)} issues from {repo}:
        ---
        {batch}
        ---

        Generate diverse question–answer pairs for each issue.
        """
    ).strip()
    
    resp = await acompletion(
    model="gpt-4.1",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": user_query},
        ],
        caching=True,
        stream=False,
        response_format=Response,
    )

    content = resp["choices"][0]["message"]["content"]  # type: ignore
    qa_pairs = Response.model_validate_json(content).questions

    return qa_pairs
    
async def generate_synthetic_data_for_repo(repo: str, batch_size: int = 20) -> List[Response]:
    """
    Generate synthetic data for a given repository.
    """
    for batch in iterate_repo_issues(repo, batch_size=batch_size):
        qa_pairs = await generate_synthetic_qa_pairs_for_repo(repo, batch)
        for qa_pair in qa_pairs:
            print(qa_pair.question)
            print(qa_pair.answer)
            print(qa_pair.repo)
            print(qa_pair.issue)
            print(qa_pair.how_realistic)
            print("-" * 100)
        
    

if __name__ == "__main__":
    import asyncio
    asyncio.run(generate_synthetic_data_for_repo("grok-ai/nn-template")) 